var c="MAX_AI_CHAT_GPT_MESSAGE_KEY",l=!1,i=[],r=window.fetch,u=(a,d)=>r(a,d).then(function(s){return new Promise(e=>{if(l&&(["https://chat.openai.com/backend-api/files","https://chat.openai.com/backend-api/conversation/interpreter/process_upload"].includes(a)||a.includes("https://chat.openai.com/backend-api/files"))){let o=s.clone(),n=a==="https://chat.openai.com/backend-api/files"?1:2;o.json().then(t=>{if(window.postMessage({event:c,type:"upload_change",data:{status:s.status,url:a,result:t,progress:n===2?100:80,done:n===2}}),n===2){t.status="error";let p=new Response(JSON.stringify(t),{status:500,statusText:"error",headers:s.headers});l=!1,e(p)}e(s)}).catch(t=>{e(s)})}else e(s)})});window.fetch=u;var h=()=>document.querySelector('input[type="file"]');window.addEventListener("message",a=>{if(a.data?.event===c){let{type:d,data:s}=a.data;switch(d){case"ping":{let{taskId:e}=s,o=!!h();window.postMessage({event:c,type:"pong",data:{taskId:e,success:o}})}break;case"upload":{let{files:e,taskId:o}=s;i=e,l=!0,window.postMessage({event:c,type:"upload_result",data:{taskId:o,success:!0}})}break;case"upload_change":{let{result:e,progress:o,done:n}=s,t=i[0];e?.file_id&&(t.uploadedFileId=e?.file_id),e.status==="success"?(t.uploadProgress=o,t.uploadStatus=n?"success":"uploading",t.uploadedUrl=e?.download_url):(t.uploadProgress=0,t.uploadStatus="error",t.uploadErrorMessage=e?.error||"upload error"),window.postMessage({event:c,type:"upload_change_result",data:{files:i}})}break;default:break}}});
